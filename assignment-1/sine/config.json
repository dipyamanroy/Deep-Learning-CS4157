{
    "mini_batch_size": 64,
    "learning_rate": 0.01,
    "num_iterations": 1000,
    "activation": "tanh",
    "cost_func": "mse",
    "regularisation": "L2",
    "lambda_reg": 0.1,
    "optimizer": "adam",
    "beta": 0.9,
    "beta1": 0.9,
    "beta2": 0.999,
    "epsilon": 1e-8,
    "layers_dims": [1, 20, 20, 1],
    "early_stopping_patience": 0
}